# 机器学习, 应用场景
* 规则难定义, 难量化描述
* 规则不断变化

# 应用案例
  * 垃圾邮件识别
  * 人脸识别
  * 数字识别, MNIST数据集

# 思考人类怎么学习
  * 经验学习: 一定的样本资料 -> 学习, 归纳, 整理, 总结 -> 知识经验 (再遇到类似任务 -> 反应)

# 机器学习算法
  * 输入大量学习资料(数据集) -> 机器学习算法 -> 模型 / f(x)  (输入样例 -> 输出结果)
  
# 机器与人类对比
  * 机器需要海量数据
  * 机器运算速度高(算力强)

# 生活中机器学习的运用
  * 信用卡风险
  * 根据输入关键字推荐
  * 商城推荐感兴趣的商品
  * 语音, 人脸识别
  * 金融预测, 量化交易, 医疗诊断, 市场分析
  
# 未来运用领域
  * 无人驾驶
  * 安全领域
  * 医疗领域, 辅助诊疗
  * 金融, 市场领域
  * 自然语言处理, 智能翻译
  * 各种专有领域: 矿产勘查, 宇宙探索, 药物研发, ...
  * 未来基本技能

# 课程主要内容
  * kNN(k近临算法)
  * 线性回归
  * 多项式回归
  * 逻辑回归
  * 模型正则化
  * PCA
  * SVM
  * 决策树
  * 随机森林
  * 集成学习
  * 模型选择
  * 模型调试

# 名词
  * 人工智能 = 机器学习算法 + 搜索策略算法 + ...
  * 机器学习算法 = 监督学习 + 非监督学习 + 深度学习 + ...
  * 深度学习 = 神经网络 + ...

# 学习方式
  * 深入理解算法基本原理
  * 实际使用算法解决真实场景的问题
  * 对不同算法进行对比试验
  * 对同一算法的不同参数进行对比试验(调参)

# 如何使用算法
  * 如何评价算法的好坏
  * 如何解决拟合与欠拟合
  * 如何调节算法的参数
  * 如何验证算法的正确性

# 关于调库
  * 了解概念原理
  * 深入理解
  * 优化创新

# 主要技术栈
  * 语言: Python3
  * 框架: Scikit-learn
  * 其他: numpy, matplotlib, ...
  * IDE: Jpyter Notebook, PyCharm
  * 环境搭建: ANACONDA

# 基础
  * Python3
  * 高等数学
  * 线性代数
  * 概率统计

# 数据集 datasets
  * scikit-learn内置数据集或者通过其可下载的数据集
  
# 整体
  * 数据准备到实际应用是个庞大繁琐的过程
  * 真实世界数据预处理

# 专门领域的机器学习任务
  * 视觉领域
  * 推荐系统
  * 自然语言处理
  * 时间序列分析

# 机器学习基础概念

## 关于数据
* 数据整体叫做数据集 dataset
* 每一行数据称为一个样本sample, 或者叫特征向量
* 第i个样本行写作大写矩阵X(上角标i, 下角标j为第j个特征值)
* 除最后一列, 表达样本的特征feature
* 最后一列, 称为标记label, 表示为小写向量y(上角标i表示第i个样本的标记)
* 特征空间(feature space)
* 分类任务本质就是在特征空间中切分

## 特征可以很抽象
  * 图像, 每个像素点都是特征
  * 28 * 28 的图像有784个特征
  * 如果是彩色图形特征更多
  * 深度学习有算法自动的帮我们进行特征工程

## 分类任务
  * 二分类, 不是啥就是啥, 如邮件是否为垃圾邮件, 股票涨/跌
  * 多分类任务, 如手写数字识别, 图像识别, 风险评级
  * 很复杂的任务可以转为多分类任务, 比如游戏机器人, self-driving
  * 很多多分类任务可以转换成二分类任务
  * 一些算法只能完成二分类任务, 一些算法可以完成多分类任务
  * 前沿的机器学习还有多标签分类, 如一张图片上有多人, 如分析图片语义

## 另一类数据
  * 回归任务: 结果是一个连续数字, 而非类别, 如房屋价格, 市场分析, 学生成绩, 股票价格
  * 有些算法只能解决回归问题, 有些算法只能解决分类问题, 有些算法可以解决两者
  * 有些回归任务可以简化为分类任务

## 机器学习的基本任务
  1. 监督学习: 给机器的训练数据拥有标记或者答案, 正确答案的划分称为监督信息, 如图像识别, 信用评估, 医疗诊断, 房价
     * 分类任务
     * 回归任务
  2. 非监督学习: 给机器的训练数据没有标记或答案, 
    作用:
      * 对没有标记的数据进行数据分类-聚类分析, 如电商用户分类
      * 对数据进行降维处理, 包括特征提取(如信用卡的信用评级和人体重无关)和特征压缩PCA, 降维处理可以方便可视化
      * 异常检测
  3. 半监督学习: 一部分数据有标记或者答案, 另一部分数据没有,
         因为各种原因产生的标记缺失
         通常先使用无监督学习对数据做处理, 再使用监督学习做模型训练和预测
  4. 增强学习: 根据周围环境, 采取行动, 根据反馈, 学习行动方式
        适合机器人, AlphaGo
        无人驾驶, 机器人
        监督学习和半监督学习是增强学习的基础

## 机器学习, 根据生产环境是否对模型优化, 来划分
  * 批量学习, 如手写识别系统
      优点: 简单
      问题: 如何适应环境变化
      解决: 定时重新批量学习
      缺点: 1. 每次重新批量学习, 运算量巨大
           2. 某些环境变化非常快, 如股市
  * 在线学习, 输入样例不被浪费掉
      优点: 及时反映新的环境变化
      问题: 生产环境有脏数据 
      解决: 加强对数据的监控
      其他: 适用于数据量巨大, 完全无法批量学习的环境

## 参数
  * 参数学习, 一旦学到了参数, 就不再需要原有的数据集
  * 



